{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bayesian Optimization 실습","provenance":[{"file_id":"1OYOPGOK_SaO-dV1DZWjtTYiiK0-GeE48","timestamp":1648443855333}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"3VJ5JOrHYbTv"},"source":["# 데이터 다운로드 링크로 데이터를 코랩에 불러옵니다.\n","\n","!wget 'https://bit.ly/3i4n1QB'\n","\n","import zipfile\n","with zipfile.ZipFile('3i4n1QB', 'r') as existing_zip:\n","    existing_zip.extractall('data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jq0dehQVYhPN"},"source":["# 라이브러리 불러오기\n","\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import accuracy_score\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZD-bpp0JYipI"},"source":["# 데이터를 불러와 학습시킬 준비하기\n","\n","train = pd.read_csv('data/train.csv')\n","test = pd.read_csv('data/test.csv')\n","\n","# Scailing\n","scaler = MinMaxScaler()\n","scaler.fit(train[['fixed acidity']])\n","train['Scaled fixed acidity'] = scaler.transform(train[['fixed acidity']])\n","test['Scaled fixed acidity'] = scaler.transform(test[['fixed acidity']])\n","\n","# Encoding\n","encoder = OneHotEncoder()\n","encoder.fit(train[['type']])\n","onehot = encoder.transform(train[['type']])\n","onehot = onehot.toarray()\n","onehot = pd.DataFrame(onehot)\n","onehot.columns = encoder.get_feature_names()\n","train = pd.concat([train, onehot], axis = 1)\n","train = train.drop(columns = ['type'])\n","\n","onehot = encoder.transform(test[['type']])\n","onehot = onehot.toarray()\n","onehot = pd.DataFrame(onehot)\n","onehot.columns = encoder.get_feature_names()\n","test = pd.concat([test, onehot], axis = 1)\n","test = test.drop(columns = ['type'])\n","\n","test.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-Zob-z6YkE6"},"source":["pip install bayesian-optimization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_JXV_44YmR0"},"source":["# Bayesian Optimization 불러오기\n","from bayes_opt import BayesianOptimization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgFQAEcwfPgh"},"source":["# X에 학습할 데이터를, y에 목표 변수를 저장해주세요\n","X = train.drop(columns = ['index', 'quality'])\n","y = train['quality']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pgXlkfhfPg-"},"source":["# 랜덤포레스트의 하이퍼 파라미터의 범위를 dictionary 형태로 지정해주세요\n","## Key는 랜덤포레스트의 hyperparameter이름이고, value는 탐색할 범위 입니다.\n","rf_parameter_bounds = {\n","                      'max_depth' : (1,3), # 나무의 깊이\n","                      'n_estimators' : (30,100),\n","                      }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71F1yUPOfPg-"},"source":["# 함수를 만들어주겠습니다.\n","# 함수의 구성은 다음과 같습니다.\n","# 1. 함수에 들어가는 인자 = 위에서 만든 함수의 key값들\n","# 2. 함수 속 인자를 통해 받아와 새롭게 하이퍼파라미터 딕셔너리 생성\n","# 3. 그 딕셔너리를 바탕으로 모델 생성\n","# 4. train_test_split을 통해 데이터 train-valid 나누기\n","# 5 .모델 학습\n","# 6. 모델 성능 측정\n","# 7. 모델의 점수 반환\n","\n","def rf_bo(max_depth, n_estimators):\n","  rf_params = {\n","              'max_depth' : int(round(max_depth)),\n","               'n_estimators' : int(round(n_estimators)),      \n","              }\n","  rf = RandomForestClassifier(**rf_params)\n","\n","  X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size = 0.2, )\n","\n","  rf.fit(X_train,y_train)\n","  score = accuracy_score(y_valid, rf.predict(X_valid))\n","  return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uH7JRlQ7fPg_"},"source":["# 이제 Bayesian Optimization을 사용할 준비가 끝났습니다.\n","# \"BO_rf\"라는 변수에 Bayesian Optmization을 저장해보세요\n","BO_rf = BayesianOptimization(f = rf_bo, pbounds = rf_parameter_bounds,random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5E0nc4ZhfPg_"},"source":["# Bayesian Optimization을 실행해보세요\n","BO_rf.maximize(init_points = 5, n_iter = 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILT73HuEfPhB"},"source":["# 하이퍼파라미터의 결과값을 불러와 \"max_params\"라는 변수에 저장해보세요\n","max_params = BO_rf.max['params']\n","\n","max_params['max_depth'] = int(max_params['max_depth'])\n","max_params['n_estimators'] = int(max_params['n_estimators'])\n","print(max_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yqZy4j3fPhC"},"source":["# Bayesian Optimization의 결과를 \"BO_tuend_rf\"라는 변수에 저장해보세요\n","BO_tuend_rf = RandomForestClassifier(**max_params)"],"execution_count":null,"outputs":[]}]}