{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"교차검증이란?","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOCsnoFPOF3UO8xR2uvS4vg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Hold-out**\n","\n","Hold-out은 단순하게 Train 데이터를 (train, valid)라는 이름의 2개의 데이터로 나누는 작업입니다.\n","\n","보통 train : valid = 8:2 혹은 7:3의 비율로 데이터를 나눕니다.\n","\n","데이터를 이렇게 나누는 이유는 무엇일까요?\n","\n","바로 예측 성능을 가늠해보기 위해서 입니다.\n","\n","\n","다만 Hold-out의 문제점은 데이터의 낭비입니다.\n","\n","데이터 사이언스에 있어서, 데이터는 소중한 자원입니다.\n","\n","하지만 단순하게 trian과 test로 분할하게 된다면, 20%의 데이터는 모델이 학습할 기회도 없이, 예측만하고 버려지게 됩니다.\n","\n","그래서 \"모든 데이터를 학습하게 해보자!\"라는 생각에서 나온 것이 \"교차검증\", 즉 K-Fold입니다.\n","\n","\n","\n","**교차검증**\n","\n","K-Fold의 아이디어는 단순합니다. \n","\n","\"모든 데이터를 최소한 한 번씩 다 학습하게 하자!\"\n","\n","그래서 valid 데이터를 겹치지 않게 나누어 N개의 데이터셋을 만들어 냅니다.\n","\n","\n","\n","\n","\n","만약 데이터셋을 5개로 만든다고 하면, (== valid size가 20%) 겹치지 않게 위와 같은 모양으로 만들 수 있습니다.\n","\n","그리고 반복문을 통해서 1번부터 5번 데이터들에 들어갔다가 나오면서, 데이터를 모두 최소한 한번씩은 학습할 수 있겠죠?\n","\n","자 여기까지가 교차검증에 대한 개념이었습니다.\n","\n","얘가 말을 잘못했는데 다시말하자면 5섹션으로 나눠서 각 섹션에 대해 80%로학습 20%로예측을 반복한다는 거다. 이후 최빈값을 결과값으로 결정하는 것.\n"],"metadata":{"id":"CEy5rKjnIqfb"}},{"cell_type":"markdown","source":["1. K-Fold를 이용해서 Train과 Valid Data를 나눈다.\n","2. Model을 이용해서 train 데이터를 학습한다.\n","3. Model을 이용해서 valid 데이터를 예측해 성능을 확인한다.\n","4. Model을 이용해서 test 데이터를 예측한다.\n","5. n_splits를 5로 설정한다면, 5개의 결과값들에 대한 “최빈값”을 이용해 가장 등장할 가능성이 높은 결과값으로 결정한다.\n","6. 결과를 제출한다.\n","\n","--------------------------------------------------------------------------------------------------------------------------\n","\n","# \"X\"라는 변수에 train의 \"index\"와 \"quality\"를 제외하고 지정해 주세요\n","\n","# \"y\"라는 변수에는 \"quality\"를 지정해 주세요\n","\n","X = train.drop(columns = ['index','quality'])\n","\n","y = train['quality']\n","\n","# \"kf\"라는 변수에 KFold를 지정해 줍시다.\n","\n","# n_splits는 5, shuffle은 True, random_state는 0으로 설정해주세요\n","\n","kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n","\n","# \"model\"이라는 변수에 RandomForestClassifier를 지정해 줍시다.\n","\n","# valid_scores라는 빈 리스트를 하나 만들어줍시다.\n","\n","# test_predictions라는 빈 리스트를 하나 만들어 줍시다.\n","\n","model = RandomForestClassifier(random_state = 0)\n","\n","valid_scores = []\n","\n","test_predictions = []\n","\n","# 지난 시간에 다루었던 kf.split()을 활용해, 반복문으로 X_tr, y_tr, X_val, y_val을 설정해봅시다.\n","\n","for train_idx, valid_idx in kf.split(X,y) : \n","\n"," X_tr = X.iloc[train_idx]\n","\n"," y_tr = y.iloc[train_idx]\n","\n"," X_val = X.iloc[valid_idx]\n","\n"," y_val = y.iloc[valid_idx]\n","\n","# 앞의 문제에 이어서 반복문 속에서 model.fit(X_tr, y_tr)을 활용해 모델을 학습해봅시다\n","\n","for train_idx, valid_idx in kf.split(X,y) : \n","\n","  X_tr = X.iloc[train_idx]\n","\n","  y_tr = y.iloc[train_idx]\n","\n","  X_val = X.iloc[valid_idx]\n","\n","  y_val = y.iloc[valid_idx]\n","\n","  model.fit(X_tr, y_tr)\n","\n","# 앞의 문제에 이어서 반복문 속에서 \"valid_prediction\"이라는 변수에 model.predict(X_val)의 결과를 저장해 봅시다. \n","\n","for train_idx, valid_idx in kf.split(X,y) : \n","\n","  X_tr = X.iloc[train_idx]\n","\n","  y_tr = y.iloc[train_idx]\n","\n","  X_val = X.iloc[valid_idx]\n","\n","  y_val = y.iloc[valid_idx]\n","\n","  model.fit(X_tr, y_tr)\n","\n","  valid_prediction = model.predict(X_val)\n","\n","# 앞의 문제에 이어서 반복문 속에서 accuracy_score를 이용해, 모델이 어느정도의 예측 성능이 나올지 확인해봅시다.\n","\n","# 그리고 \"valid_prediction\"의 점수를 scores에 저장 해봅시다. \n","\n","# 반복문에서 빠져나온 후에 np.mean()을 활용해 평균 점수를 예측해봅시다.\n","\n","for train_idx, valid_idx in kf.split(X,y) : \n","\n","  X_tr = X.iloc[train_idx]\n","\n","  y_tr = y.iloc[train_idx]\n","\n","  X_val = X.iloc[valid_idx]\n","\n","  y_val = y.iloc[valid_idx]\n","\n","  model.fit(X_tr, y_tr)\n","\n","  valid_prediction = model.predict(X_val)\n","\n","  score = accuracy_score(y_val, valid_prediction)\n","\n","  valid_scores.append(score)\n","\n","  print(score)\n","\n","print('평균 점수 : ', np.mean(valid_scores))\n","\n","# 이제 어느정도의 성능이 나올지 알게 되었으니, 반복문 속에서 test를 예측해 \"test_prediction\"이라는 변수에 지정해봅시다.\n","\n","# test_prediction을 지정했다면, \"test_precitions\"라는 빈 리스트에 넣어줍시다.\n","\n","for train_idx, valid_idx in kf.split(X,y) : \n","\n","  X_tr = X.iloc[train_idx]\n","\n","  y_tr = y.iloc[train_idx]\n","\n","  X_val = X.iloc[valid_idx]\n","\n","  y_val = y.iloc[valid_idx]\n","\n","  model.fit(X_tr, y_tr)\n","\n","  test_prediction = model.predict(test.drop(columns = ['index']))\n","\n","  test_predictions.append(test_prediction)\n","\n","# 이제 결과 값을 만들어 보겠습니다.\n","\n","# \"test_precitions\"를 Data Frame으로 만들어주세요\n","\n","test_predictions = pd.DataFrame(test_predictions)\n","\n","# DF.mode()를 활용해 열별 최빈값을 확인하고, \"test_prediction\"이라는 변수에 지정해봅시다.\n","\n","# \"test_prediction\"의 첫 행을 최종 결과값으로 사용합시다.\n","\n","test_prediction = test_predictions.mode()\n","\n","test_prediction = test_predictions.values[0]\n","\n","# data의 sample_submission 파일을 불러와 \"quality\"라는 변수에 \"test_precition\"을 저장해줍시다.\n","\n","# 그 이후에는, \"data/submission_KFOLD.csv\"에 저장하고, 제출해봅시다.\n","\n","sample_submission = pd.read_csv('data/sample_submission.csv')\n","\n","sample_submission['quality'] = test_prediction\n","\n","sample_submission.to_csv('data/submission_KFOLD.csv', index=False)\n","\n","뭐라는지 모르겠다아아"],"metadata":{"id":"kpy8HxORK_nq"}}]}